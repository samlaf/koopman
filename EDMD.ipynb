{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we look at (extended) dynamic mode composition, and its relation to Koopman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first toy example is taken from Clarence Rowley's talk\n",
    "#### https://ipam.wistia.com/medias/sl5hs1srxf (~21:30)\n",
    "We start with the following $z=F(z)$ dynamics\n",
    "$$\n",
    "\\begin{bmatrix} z_1 \\\\\n",
    "                z_2 \n",
    "                \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \\lambda z_1 \\\\\n",
    "               \\mu z_2 + (\\lambda^2 - \\mu)cz_1^2\n",
    "               \\end{bmatrix}\n",
    "$$\n",
    "The Koopman operator $U$ is then defined on observables by $U\\phi = \\phi \\circ F$. \\\n",
    "The eigenvalues of $U$ are $\\lambda$ and $\\mu$ and their respective eigenfunctions (eigenobservables) are \n",
    "$$ \\phi_\\lambda(z) = z_1 $$\n",
    "$$ \\phi_\\mu(z) = z_2 - cz_1^2 $$\n",
    "We can use DMD to recover the eigenvalues.\n",
    "\n",
    "We start with a dataset of points $Z = \\begin{bmatrix} z^{(1)} z^{(2)} \\dots z^{(n-1)} \\end{bmatrix}$, and let $Z' = F(Z) = \\begin{bmatrix} z^{(2)} z^{(3)} \\dots z^{(n)} \\end{bmatrix}$ \\\n",
    "We form the observation matrices $X = g(Z)$, $Y = g(Z')$ \\\n",
    "And then learn $A$ to relate these by $Y=AX$. \\\n",
    "It then turns out that the eigenvalues of $A$ are also eigenvalues of $U$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamics (forward map) function\n",
    "def F(z, lmbda=0.9, mu=0.5, c=1):\n",
    "    z1,z2 = z\n",
    "    newz = [lmbda*z1, mu*z2 + (lmbda**2 - mu)*c*z1**2]\n",
    "    return np.array(newz)\n",
    "def obs(z,obs_dct):\n",
    "    observations = [g(z) for g in obs_dct]\n",
    "    return np.array(observations)\n",
    "obs_dct1 = [ \n",
    "    lambda z: z[0], \n",
    "    lambda z: z[1] \n",
    "]\n",
    "obs_dct2 = [\n",
    "    lambda z: z[0],\n",
    "    lambda z: z[1],\n",
    "    lambda z: z[0]**2\n",
    "]\n",
    "obs_dct3 = [\n",
    "    lambda z: z[0],\n",
    "    lambda z: z[1],\n",
    "    lambda z: z[1]**2\n",
    "]\n",
    "Z = np.array([[-5,5],[-1,1],[1,1],[5,5]]).T # data points\n",
    "# But different datasets give different results! (sometimes better, sometimes worst)\n",
    "# Z = np.array([[-5,-5],[-1,-1],[-1,1],[-5,5]]).T\n",
    "# Z = np.array([[-5,-5],[-1,-1],[-1,1],[-5,5]]).%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues discovered [0.9 0.5]\n"
     ]
    }
   ],
   "source": [
    "# First we test the linear case (c=0), which looks like\n",
    "# F = [0.9   0]\n",
    "#     [0.  0.5]\n",
    "obs_dct = obs_dct1 # choose dictionary of observables\n",
    "FZ = np.apply_along_axis(lambda z: F(z,c=0),0,Z)\n",
    "X = np.apply_along_axis(lambda z: obs(z,obs_dct),0,Z)\n",
    "Y = np.apply_along_axis(lambda z: obs(z,obs_dct),0,FZ)\n",
    "\n",
    "# We learn A st Y=AX\n",
    "A = Y @ np.linalg.pinv(X)\n",
    "D,Q = np.linalg.eig(A)\n",
    "print(\"Eigenvalues discovered\", D) # sure enough we recover the eigenvalues (but other datasets may fail!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9        2.00230769]\n"
     ]
    }
   ],
   "source": [
    "# Then we test with c=1 (doesn't work because observables (z1,z2) not rich enough!)\n",
    "obs_dct = obs_dct1 # choose dictionary of observables\n",
    "FZ = np.apply_along_axis(F,0,Z)\n",
    "X = np.apply_along_axis(lambda z: obs(z,obs_dct),0,Z)\n",
    "Y = np.apply_along_axis(lambda z: obs(z,obs_dct),0,FZ)\n",
    "\n",
    "# We learn A st Y=AX\n",
    "A = Y @ np.linalg.pinv(X)\n",
    "D,Q = np.linalg.eig(A)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9  0.5  0.81]\n"
     ]
    }
   ],
   "source": [
    "# Now we try with 2nd dictionary of observables (z1,z2,z1^2)\n",
    "obs_dct = obs_dct2 # choose dictionary of observables\n",
    "FZ = np.apply_along_axis(F,0,Z)\n",
    "X = np.apply_along_axis(lambda z: obs(z,obs_dct),0,Z)\n",
    "Y = np.apply_along_axis(lambda z: obs(z,obs_dct),0,FZ)\n",
    "\n",
    "# We learn A st Y=AX\n",
    "A = Y @ np.linalg.pinv(X)\n",
    "D,Q = np.linalg.eig(A)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9        0.82205673 4.76704327]\n"
     ]
    }
   ],
   "source": [
    "# Now we try with 3rd dictionary of observables (z1,z2,z2^2) -- z2^2 is  not good enough to recover 2nd eval\n",
    "obs_dct = obs_dct3 # choose dictionary of observables\n",
    "FZ = np.apply_along_axis(F,0,Z)\n",
    "X = np.apply_along_axis(lambda z: obs(z,obs_dct),0,Z)\n",
    "Y = np.apply_along_axis(lambda z: obs(z,obs_dct),0,FZ)\n",
    "\n",
    "# We learn A st Y=AX\n",
    "A = Y @ np.linalg.pinv(X)\n",
    "D,Q = np.linalg.eig(A)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our second toy example is a Linear system : example 4.1 in the EDMD paper\n",
    "If $ x_{n+1} = Tx_n $, and that $T$ is diagonalizable with eigenvector/value pairs $(v_i,\\lambda_i)$ such that $Tv_i = \\lambda_iv_i$.  \n",
    "We let $w_i$ be the Riesz dual basis to $v_i$, that is $\\langle w_i, v_j \\rangle = \\delta_{ij}$.  \n",
    "Surprisingly (to me at least), $w_i$ are also eigenvectors of the adjoint of $T$ with the same eigenvalues, that is $T^* w_i = \\lambda_i w_i$.  \n",
    "The eigenfunctions of the Koopman operator are then\n",
    "$$ \\phi_{n_1,\\dots,n_N}(x) = \\prod_{i=1}^N \\langle w_i, x \\rangle^{n_i}$$\n",
    "\n",
    "In the paper, they resolve everything into an orthonormal basis (and for eg. write $w_i^* v_j = \\delta_{ij}$ and that $w_i$'s are left eigenvectors of $J$ (the matrix representation of $T$ in that orthonormal basis). I prefer the abstract notation, independent of a basis choice. This is also what is used in the Applied Koopmanism paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import eval_hermite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamics\n",
    "A = np.array([[0.9, -0.1],\n",
    "              [0.,   0.8]])\n",
    "\n",
    "# Observations\n",
    "def create_hermite(n,m):\n",
    "    return lambda x,y: eval_hermite(n,x) * eval_hermite(m,y)\n",
    "deg = 4\n",
    "obs_dct = [create_hermite(i,j) for i in range(deg) for j in range(deg)]\n",
    "def obs(z,obs_dct):\n",
    "    x,y = z\n",
    "    observations = [g(x,y) for g in obs_dct]\n",
    "    return np.array(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        +0.j        , 0.28984258+0.j        ,\n",
       "       0.3890866 +0.09585266j, 0.3890866 -0.09585266j,\n",
       "       0.50305358+0.10293423j, 0.50305358-0.10293423j,\n",
       "       0.81      +0.j        , 0.9       +0.j        ,\n",
       "       0.72      +0.j        , 0.66437998+0.j        ,\n",
       "       0.64      +0.j        , 0.8       +0.j        ,\n",
       "       0.729     +0.j        , 0.648     +0.j        ,\n",
       "       0.576     +0.j        , 0.512     +0.j        ])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random data\n",
    "Z = np.random.randn(2,100)\n",
    "FZ = A@Z\n",
    "\n",
    "# Evaluate the observables\n",
    "X = np.apply_along_axis(lambda z: obs(z,obs_dct),0,Z)\n",
    "Y = np.apply_along_axis(lambda z: obs(z,obs_dct),0,FZ)\n",
    "\n",
    "# Fit the Koopman matrix and find it's eigenvalues\n",
    "K = Y @ np.linalg.pinv(X)\n",
    "D,V = np.linalg.eig(K)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that we find the same top eigenvalues as in the EDMD paper\n",
    "![edmd_eigenvalues](edmd_linearsys_eigenvalues.png)\n",
    "\n",
    "I'm not sure how to explain the complex eigenvalues (I think Koopman is a positive self-adjoint operator and hence should only have real positive eigenvalues). Might be from numerical errors/approximations. Here's part of the spectrum found in the paper. Still not sure how to interpret it.\n",
    "![edmd_spectrum](edmd_fig4_spectrum.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
